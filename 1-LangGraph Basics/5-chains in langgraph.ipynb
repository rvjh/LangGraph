{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd0221c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "790081e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6028910",
   "metadata": {},
   "source": [
    "#### messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba287931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: LLMModel\n",
      "\n",
      "Hello! how can i help you?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: User\n",
      "\n",
      "Can you tell me a joke?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: LLMModel\n",
      "\n",
      "which programming languare you want to learn\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: User\n",
      "\n",
      "i want to learn python language\n"
     ]
    }
   ],
   "source": [
    "messages = [AIMessage(content= f\"Hello! how can i help you?\", name = \"LLMModel\")]\n",
    "messages.append(HumanMessage(content= f\"Can you tell me a joke?\", name = \"User\"))\n",
    "messages.append(AIMessage(content= f\"which programming languare you want to learn\", name = \"LLMModel\"))\n",
    "messages.append(HumanMessage(content= f\"i want to learn python language\", name = \"User\"))\n",
    "\n",
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f853ca3",
   "metadata": {},
   "source": [
    "## chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c67d4bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, the user asked for a joke, but I mistakenly asked about a programming language instead of telling a joke. Now they want to learn Python. Let me correct my mistake first by acknowledging that I should have told a joke. Then, I need to pivot into helping them with Python. I should start with a simple joke to show I can do that, then proceed to offer Python learning assistance. Let me make sure the joke is appropriate and the transition flows naturally. Also, I should keep it friendly and encouraging for a beginner. Maybe start with a basic joke, then ask if they want to learn Python or another joke. That gives them a choice and shows I can help with either. Alright, let's put that together.\\n</think>\\n\\nAh, Python is a fantastic choice! Let me start with a light joke to warm up before diving into coding:\\n\\n**Joke:** Why do programmers prefer dark mode?  \\nBecause light attracts bugs! üêõ\\n\\nNow, if you're ready to learn Python, I can help! What would you like to explore first?  \\n- Basics (variables, loops, etc.)  \\n- Data structures (lists, dictionaries)  \\n- Functions and modules  \\n- Or maybe a fun project (like a calculator or game)?  \\n\\nJust let me know your goal! üòä\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model = \"qwen/qwen3-32b\"\n",
    ")\n",
    "\n",
    "llm.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "025e951c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 384,\n",
       "  'prompt_tokens': 57,\n",
       "  'total_tokens': 441,\n",
       "  'completion_time': 0.884246037,\n",
       "  'completion_tokens_details': None,\n",
       "  'prompt_time': 0.002124698,\n",
       "  'prompt_tokens_details': None,\n",
       "  'queue_time': 0.046092612,\n",
       "  'total_time': 0.886370735},\n",
       " 'model_name': 'qwen/qwen3-32b',\n",
       " 'system_fingerprint': 'fp_5cf921caa2',\n",
       " 'service_tier': 'on_demand',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None,\n",
       " 'model_provider': 'groq'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(messages).response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f35cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangGraphv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
